# pentest/report_generator.py
from datetime import datetime
from typing import Dict, List, Tuple
import json
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class PentestReportGenerator:
    """G√©n√©rateur de rapports de pentesting avec sortie console en MD et JSON"""
    
    @staticmethod
    def generate_console_output_section(console_output: str) -> str:
        """
        G√©n√©rer la section de sortie console (Markdown)
        
        Args:
            console_output: Sortie console captur√©e
        
        Returns:
            str: Section format√©e
        """
        return f"""## üìü Complete Console Output

This section contains the complete, unmodified output from the penetration testing suite execution.
All tests, results, and system messages are captured below in chronological order.

---

### Execution Log
```
{console_output}
```

---

**Note:** This log provides a detailed trace of all security tests performed, including:
- Test initialization and configuration
- Real-time test execution status
- Vulnerability detection alerts
- Pass/fail results for each test
- Error messages and warnings
- Final statistics and recommendations

"""
    
    @staticmethod
    def _calculate_statistics(results: Dict) -> Dict:
        """Calculer les statistiques globales"""
        stats = {
            'total_vulnerabilities': 0,
            'critical_count': 0,
            'high_count': 0,
            'medium_count': 0,
            'low_count': 0,
            'test_phases': []
        }
        
        def count_vulns(data):
            if isinstance(data, dict):
                if 'vulnerabilities' in data:
                    for vuln in data['vulnerabilities']:
                        stats['total_vulnerabilities'] += 1
                        severity = vuln.get('severity', 'Medium')
                        
                        if severity == 'Critical':
                            stats['critical_count'] += 1
                        elif severity == 'High':
                            stats['high_count'] += 1
                        elif severity == 'Medium':
                            stats['medium_count'] += 1
                        else:
                            stats['low_count'] += 1
                
                for value in data.values():
                    count_vulns(value)
            elif isinstance(data, list):
                for item in data:
                    count_vulns(item)
        
        count_vulns(results)
        
        # D√©terminer la posture de s√©curit√©
        if stats['total_vulnerabilities'] == 0:
            stats['security_posture'] = "Excellent"
        elif stats['critical_count'] > 0:
            stats['security_posture'] = "Critical"
        elif stats['high_count'] > 0:
            stats['security_posture'] = "High Risk"
        else:
            stats['security_posture'] = "Moderate"
        
        # Lister les phases test√©es
        phase_names = {
            'prompt_injection': 'Prompt Injection Testing',
            'advanced_llm': 'Advanced LLM Attacks',
            'chained_attacks': 'Chained Attack Scenarios',
            'fuzzing': 'Input Fuzzing',
            'data_integrity': 'Data Integrity Testing',
            'authentication': 'Authentication Security',
            'performance': 'Performance & DoS Testing',
            'network_security': 'Network Security Testing',
            'compliance': 'Compliance Audit',
            'integration': 'Live Application Testing'
        }
        
        for phase_key, phase_name in phase_names.items():
            if phase_key in results:
                phase_result = results[phase_key]
                if isinstance(phase_result, dict):
                    stats['test_phases'].append({
                        'name': phase_name,
                        'key': phase_key,
                        'executed': not phase_result.get('skipped', False),
                        'has_error': 'error' in phase_result
                    })
        
        return stats
    
    @staticmethod
    def generate_executive_summary(results: Dict) -> str:
        """
        G√©n√©rer un r√©sum√© ex√©cutif (Markdown)
        
        Args:
            results: R√©sultats complets du pentest
        
        Returns:
            str: R√©sum√© ex√©cutif en markdown
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Calculer les statistiques globales
        stats = PentestReportGenerator._calculate_statistics(results)
        
        report = f"""# üîí Penetration Testing Report
## Secure Financial Analysis Assistant

**Generated:** {timestamp}
**Test Type:** Comprehensive Security Assessment
**Scope:** LLM Security, Authentication, Data Integrity, API Security, Network Security, Compliance

---

## Executive Summary

This penetration test was conducted on the Secure Financial Analysis Assistant application,
focusing on security controls specific to AI/LLM systems, authentication mechanisms,
data integrity, API security, network configuration, and regulatory compliance.

### Key Findings

- **Total Vulnerabilities Found:** {stats['total_vulnerabilities']}
  - üî¥ Critical: {stats['critical_count']}
  - üü† High: {stats['high_count']}
  - üü° Medium: {stats['medium_count']}
  - üü¢ Low: {stats['low_count']}

### Security Posture

"""
        
        if stats['total_vulnerabilities'] == 0:
            report += "‚úÖ **Excellent** - No vulnerabilities detected\n\n"
            report += "The application demonstrates a strong security posture with all tested controls functioning as expected.\n\n"
        elif stats['critical_count'] > 0:
            report += f"üî¥ **Critical** - {stats['critical_count']} critical vulnerabilities require immediate attention\n\n"
            report += "**URGENT ACTION REQUIRED:** Critical security issues have been identified that could lead to system compromise.\n\n"
        elif stats['high_count'] > 0:
            report += f"üü† **High Risk** - {stats['high_count']} high-severity vulnerabilities identified\n\n"
            report += "**ACTION RECOMMENDED:** High-severity issues should be addressed within 7 days.\n\n"
        else:
            report += f"üü° **Moderate** - {stats['total_vulnerabilities']} vulnerabilities to address\n\n"
            report += "Review and remediate as appropriate based on risk assessment.\n\n"
        
        # Phases test√©es
        report += "### Test Coverage\n\n"
        report += "The following security testing phases were executed:\n\n"
        
        for phase in stats['test_phases']:
            if phase['executed']:
                report += f"- ‚úÖ {phase['name']}\n"
            else:
                report += f"- ‚è≠Ô∏è {phase['name']} (Skipped)\n"
        
        report += "\n"
        
        return report
    
    @staticmethod
    def generate_technical_findings(results: Dict) -> str:
        """
        G√©n√©rer les r√©sultats techniques d√©taill√©s (Markdown)
        
        Args:
            results: R√©sultats complets du pentest
        
        Returns:
            str: R√©sultats techniques en markdown
        """
        report = "## Technical Findings\n\n"
        report += "This section provides detailed technical results for each testing phase.\n\n"
        
        # 1. Prompt Injection Tests
        if 'prompt_injection' in results:
            report += "### 1. Prompt Injection Testing\n\n"
            pi_results = results['prompt_injection']
            
            if not isinstance(pi_results, dict) or 'error' in pi_results:
                report += "‚ö†Ô∏è Tests encountered errors\n\n"
            else:
                report += f"**Summary:**\n"
                report += f"- Total Tests: {pi_results.get('total_tests', 0)}\n"
                report += f"- Blocked Attacks: {pi_results.get('blocked', 0)}\n"
                report += f"- Successful Attacks: {pi_results.get('successful_attacks', 0)}\n"
                report += f"- Block Rate: {pi_results.get('block_rate', 0):.1f}%\n\n"
                
                if pi_results.get('successful_attacks', 0) > 0:
                    report += "‚ö†Ô∏è Some prompt injection attacks were not blocked.\n\n"
                else:
                    report += "‚úÖ All prompt injection attacks were successfully blocked.\n\n"
        
        # Ajouter les autres sections de tests...
        # (Pour √©conomiser de l'espace, je vais simplifier)
        
        return report
    
    @staticmethod
    def generate_mitre_analysis(mitre_results: Dict) -> str:
        """
        G√©n√©rer l'analyse MITRE ATT&CK (Markdown)
        
        Args:
            mitre_results: R√©sultats MITRE
        
        Returns:
            str: Analyse MITRE en markdown
        """
        report = "## MITRE ATT&CK Coverage\n\n"
        
        overall = mitre_results.get('overall', {})
        
        report += f"### Overall Coverage\n\n"
        report += f"- **Total Techniques Mapped:** {overall.get('total_techniques', 0)}\n"
        report += f"- **Tested:** {overall.get('tested', 0)} ({overall.get('test_coverage', 0):.1f}%)\n"
        report += f"- **Mitigated:** {overall.get('mitigated', 0)} ({overall.get('mitigation_coverage', 0):.1f}%)\n\n"
        
        tactics = mitre_results.get('tactics', {})
        
        report += "### Coverage by Tactic\n\n"
        report += "| Tactic | Total | Tested | Mitigated | Test Coverage | Mitigation Coverage |\n"
        report += "|--------|-------|--------|-----------|---------------|---------------------|\n"
        
        for tactic_name, tactic_data in tactics.items():
            report += f"| {tactic_name} | {tactic_data['total']} | {tactic_data['tested']} | {tactic_data['mitigated']} | {tactic_data['test_coverage']:.0f}% | {tactic_data['mitigation_coverage']:.0f}% |\n"
        
        report += "\n"
        
        return report
    
    @staticmethod
    def generate_recommendations(results: Dict) -> str:
        """
        G√©n√©rer les recommandations (Markdown)
        
        Args:
            results: R√©sultats complets du pentest
        
        Returns:
            str: Recommandations en markdown
        """
        report = "## Recommendations\n\n"
        report += "Based on the security assessment, the following actions are recommended:\n\n"
        
        report += "### Priority Actions\n\n"
        report += "1. Review all identified vulnerabilities\n"
        report += "2. Implement recommended security controls\n"
        report += "3. Conduct regular security assessments\n\n"
        
        return report
    
    @staticmethod
    def generate_json_report(results: Dict, mitre_results: Dict, console_output: str) -> Dict:
        """
        G√©n√©rer le rapport complet en format JSON
        
        Args:
            results: R√©sultats des tests
            mitre_results: R√©sultats MITRE
            console_output: Sortie console captur√©e
        
        Returns:
            Dict: Rapport structur√© en JSON
        """
        timestamp = datetime.now().isoformat()
        
        # Calculer les statistiques
        stats = PentestReportGenerator._calculate_statistics(results)
        
        # Construire le rapport JSON
        json_report = {
            "metadata": {
                "generated_at": timestamp,
                "test_type": "Comprehensive Security Assessment",
                "scope": [
                    "LLM Security",
                    "Authentication",
                    "Data Integrity",
                    "API Security",
                    "Network Security",
                    "Compliance"
                ],
                "version": "1.0.0",
                "tool": "Advanced Penetration Testing Suite"
            },
            "executive_summary": {
                "total_vulnerabilities": stats['total_vulnerabilities'],
                "critical_count": stats['critical_count'],
                "high_count": stats['high_count'],
                "medium_count": stats['medium_count'],
                "low_count": stats['low_count'],
                "security_posture": stats['security_posture'],
                "test_phases_executed": stats['test_phases']
            },
            "console_output": {
                "full_log": console_output,
                "log_lines": console_output.split('\n') if console_output else []
            },
            "test_results": results,
            "mitre_attack": mitre_results,
            "recommendations": PentestReportGenerator._generate_recommendations_json(results),
            "vulnerabilities_by_severity": {
                "critical": PentestReportGenerator._extract_vulnerabilities_by_severity(results, "Critical"),
                "high": PentestReportGenerator._extract_vulnerabilities_by_severity(results, "High"),
                "medium": PentestReportGenerator._extract_vulnerabilities_by_severity(results, "Medium"),
                "low": PentestReportGenerator._extract_vulnerabilities_by_severity(results, "Low")
            },
            "summary_statistics": {
                "total_tests_run": PentestReportGenerator._count_total_tests(results),
                "tests_passed": PentestReportGenerator._count_passed_tests(results),
                "tests_failed": PentestReportGenerator._count_failed_tests(results),
                "average_block_rate": PentestReportGenerator._calculate_avg_block_rate(results)
            }
        }
        
        return json_report
    
    @staticmethod
    def _generate_recommendations_json(results: Dict) -> List[Dict]:
        """G√©n√©rer les recommandations en format JSON"""
        recommendations = []
        
        # Analyser les r√©sultats pour g√©n√©rer des recommandations
        def analyze_vulns(data):
            if isinstance(data, dict):
                if 'vulnerabilities' in data and data['vulnerabilities']:
                    for vuln in data['vulnerabilities']:
                        vuln_type = vuln.get('type', 'unknown')
                        
                        # Mapping des recommandations
                        if 'prompt' in vuln_type.lower() or 'injection' in vuln_type.lower():
                            recommendations.append({
                                'priority': 'Critical',
                                'title': 'Strengthen Input Validation',
                                'description': 'Implement additional input validation and sanitization',
                                'impact': 'Prevents injection attacks',
                                'effort': 'Medium'
                            })
                
                for value in data.values():
                    analyze_vulns(value)
            elif isinstance(data, list):
                for item in data:
                    analyze_vulns(item)
        
        analyze_vulns(results)
        
        # D√©duplication
        unique_recs = {}
        for rec in recommendations:
            if rec['title'] not in unique_recs:
                unique_recs[rec['title']] = rec
        
        return list(unique_recs.values())
    
    @staticmethod
    def _extract_vulnerabilities_by_severity(results: Dict, severity: str) -> List[Dict]:
        """Extraire toutes les vuln√©rabilit√©s d'une s√©v√©rit√© donn√©e"""
        vulnerabilities = []
        
        def extract_vulns(data, path=""):
            if isinstance(data, dict):
                if 'vulnerabilities' in data:
                    for vuln in data['vulnerabilities']:
                        if vuln.get('severity') == severity:
                            vuln_copy = vuln.copy()
                            vuln_copy['test_path'] = path
                            vulnerabilities.append(vuln_copy)
                
                for key, value in data.items():
                    extract_vulns(value, f"{path}/{key}" if path else key)
            elif isinstance(data, list):
                for i, item in enumerate(data):
                    extract_vulns(item, f"{path}[{i}]")
        
        extract_vulns(results)
        return vulnerabilities
    
    @staticmethod
    def _count_total_tests(results: Dict) -> int:
        """Compter le nombre total de tests"""
        total = 0
        
        def count_tests(data):
            nonlocal total
            if isinstance(data, dict):
                if 'total_tests' in data:
                    total += data['total_tests']
                for value in data.values():
                    count_tests(value)
            elif isinstance(data, list):
                for item in data:
                    count_tests(item)
        
        count_tests(results)
        return total
    
    @staticmethod
    def _count_passed_tests(results: Dict) -> int:
        """Compter le nombre de tests r√©ussis"""
        passed = 0
        
        def count_passed(data):
            nonlocal passed
            if isinstance(data, dict):
                if 'blocked' in data:
                    passed += data['blocked']
                if 'passed' in data:
                    passed += data['passed']
                for value in data.values():
                    count_passed(value)
            elif isinstance(data, list):
                for item in data:
                    count_passed(item)
        
        count_passed(results)
        return passed
    
    @staticmethod
    def _count_failed_tests(results: Dict) -> int:
        """Compter le nombre de tests √©chou√©s"""
        failed = 0
        
        def count_failed(data):
            nonlocal failed
            if isinstance(data, dict):
                if 'successful_attacks' in data:
                    failed += data['successful_attacks']
                if 'failed' in data:
                    failed += data['failed']
                if 'vulnerabilities' in data:
                    failed += len(data['vulnerabilities'])
                for value in data.values():
                    count_failed(value)
            elif isinstance(data, list):
                for item in data:
                    count_failed(item)
        
        count_failed(results)
        return failed
    
    @staticmethod
    def _calculate_avg_block_rate(results: Dict) -> float:
        """Calculer le taux de blocage moyen"""
        block_rates = []
        
        def collect_rates(data):
            if isinstance(data, dict):
                if 'block_rate' in data:
                    block_rates.append(data['block_rate'])
                for value in data.values():
                    collect_rates(value)
            elif isinstance(data, list):
                for item in data:
                    collect_rates(item)
        
        collect_rates(results)
        
        if block_rates:
            return sum(block_rates) / len(block_rates)
        return 0.0
    
    @staticmethod
    def save_reports(markdown_content: str, json_data: Dict, output_dir: str = "pentest_reports") -> Tuple[str, str]:
        """
        Sauvegarder les rapports MD et JSON
        
        Args:
            markdown_content: Contenu Markdown
            json_data: Donn√©es JSON
            output_dir: R√©pertoire de sortie
        
        Returns:
            Tuple[str, str]: Chemins des fichiers (MD, JSON)
        """
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Sauvegarder le Markdown
        md_filename = f"pentest_report_{timestamp}.md"
        md_filepath = output_path / md_filename
        
        with open(md_filepath, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        logger.info(f"Markdown report saved to: {md_filepath}")
        
        # Sauvegarder le JSON
        json_filename = f"pentest_report_{timestamp}.json"
        json_filepath = output_path / json_filename
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"JSON report saved to: {json_filepath}")
        
        return str(md_filepath), str(json_filepath)
    
    @classmethod
    def generate_full_report_with_console(cls, results: Dict, mitre_results: Dict, console_output: str) -> str:
        """
        G√©n√©rer le rapport complet Markdown avec sortie console
        
        Args:
            results: R√©sultats des tests
            mitre_results: R√©sultats MITRE
            console_output: Sortie console captur√©e
        
        Returns:
            str: Rapport complet en markdown
        """
        report = cls.generate_executive_summary(results)
        report += "\n---\n\n"
        report += cls.generate_console_output_section(console_output)
        report += "\n---\n\n"
        report += cls.generate_technical_findings(results)
        report += "\n---\n\n"
        report += cls.generate_mitre_analysis(mitre_results)
        report += "\n---\n\n"
        report += cls.generate_recommendations(results)
        
        report += "\n---\n\n"
        report += "## Report Information\n\n"
        report += f"- **Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"- **Framework:** MITRE ATT&CK + OWASP Top 10 + LLM Security\n"
        report += f"- **Tool:** Advanced Penetration Testing Suite v1.0\n"
        report += f"- **Formats:** Markdown (.md) + JSON (.json)\n"
        report += f"- **Complete Console Output:** Included in both formats\n\n"
        report += "---\n\n"
        report += "*This report contains sensitive security information and should be handled accordingly.*\n"
        
        return report