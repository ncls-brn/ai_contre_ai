"""
Exercice 3: Analyse & StratÃ©gie de DÃ©fense
=============================================
Objectif: Appliquer concepts Ã  cas rÃ©el cybersÃ©curitÃ©

Temps: 15 minutes
- Lecture scÃ©nario: 2 min
- Threat assessment: 5 min
- Proposer dÃ©fense: 5 min
- Visualiser analyse: 3 min

ScÃ©nario rÃ©aliste: DÃ©tecteur malware bancaire face menace adversarial
"""

import torch
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Rectangle
import os

print("=" * 80)
print("EXERCICE 3: ANALYSE & STRATÃ‰GIE DE DÃ‰FENSE")
print("=" * 80)

# ============================================================================
# PRÃ‰SENTATION SCÃ‰NARIO
# ============================================================================

print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    SCÃ‰NARIO RÃ‰ALISTE: SÃ‰CURITÃ‰ BANCAIRE                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONTEXTE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€
Vous Ãªtes Security Engineer chez BankCorp France (banque rÃ©gionale)

SystÃ¨me existant:
  â€¢ DÃ©tecteur malware ML-based
  â€¢ EntraÃ®nÃ© sur 500,000 fichiers (2019-2023)
  â€¢ DÃ©ployÃ© en production: analyse 10,000 fichiers/jour
  â€¢ Performance: 98% accuracy, 96% recall, 99% precision

MENACE IDENTIFIÃ‰E (Renseignement interne):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Groupe attaquant "APT-SecureBank":
  1. RÃ©cupÃ¨re le modÃ¨le (via reverse engineering/API)
  2. GÃ©nÃ¨re malware adversarial
  3. Contourne dÃ©tecteur BankCorp
  4. Propage malware â†’ clients BankCorp
  5. Vole donnÃ©es, ~â‚¬10M+ potential damage

VOTRE MISSION (Urgent!):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Ã‰valuer risque rÃ©aliste
2. Proposer dÃ©fense pragmatique (5 couches)
3. Quantifier efficacitÃ©
4. Recommander Ã  Board direction
5. Justifier investissement â‚¬100k

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# ============================================================================
# PARTIE 1: THREAT ASSESSMENT
# ============================================================================

print("\n[STEP 1] Ã‰valuation menace adversarial (Threat Assessment)...\n")

class ThreatAssessment:
    """
    Ã‰valuer probabilitÃ© + impact attaque adversarial
    Utilise framework: CVSS-like scoring
    """
    
    def __init__(self):
        self.factors = {}
        self.scores = {}
    
    def assess_feasibility(self):
        """FaisabilitÃ© technique"""
        print("1. FAISABILITÃ‰ TECHNIQUE")
        print("   Peut-on gÃ©nÃ©rer malware adversarial?")
        print()
        
        methods = {
            'FGSM': {
                'complexity': 'TrÃ¨s basse',
                'time': '5 minutes',
                'code_lines': '< 50',
                'knowledge': 'Basique (ML 101)',
                'success_rate': '50-70%',
                'score': 9
            },
            'PGD (itÃ©ratif)': {
                'complexity': 'Basse',
                'time': '15 minutes',
                'code_lines': '< 100',
                'knowledge': 'IntermÃ©diaire',
                'success_rate': '75-85%',
                'score': 8
            },
            'Black-Box Attack': {
                'complexity': 'Moyenne',
                'time': '1-2 heures',
                'code_lines': '200-500',
                'knowledge': 'AvancÃ©',
                'success_rate': '85-95%',
                'score': 7
            }
        }
        
        for method, details in methods.items():
            print(f"   {method}:")
            print(f"     â€¢ ComplexitÃ©: {details['complexity']}")
            print(f"     â€¢ Temps: {details['time']}")
            print(f"     â€¢ Lignes code: {details['code_lines']}")
            print(f"     â€¢ Connaissances requises: {details['knowledge']}")
            print(f"     â€¢ Taux succÃ¨s: {details['success_rate']}")
            print(f"     â€¢ Score faisabilitÃ©: {details['score']}/10")
            print()
        
        avg_score = np.mean([d['score'] for d in methods.values()])
        self.scores['feasibility'] = avg_score
        
        print(f"   âœ“ Score faisabilitÃ© MOYEN: {avg_score:.1f}/10")
        print(f"     â†’ VERDICT: TRÃˆS FAISABLE pour attaquant motivÃ©\n")
        
        return avg_score
    
    def assess_motivation(self):
        """Motivation attaquant"""
        print("2. MOTIVATION ATTAQUANT")
        print("   Pourquoi cibler BankCorp?")
        print()
        
        motivations = {
            'Gain financier': {
                'potential': 'Millions â‚¬ (vol donnÃ©es, ranÃ§on)',
                'likelihood': 'TrÃ¨s Ã©levÃ©e',
                'effort': 'ModÃ©rÃ©',
                'score': 10
            },
            'Avantage compÃ©titif': {
                'potential': 'Technologie, secrets commerciaux',
                'likelihood': 'Ã‰levÃ©e',
                'effort': 'ModÃ©rÃ©',
                'score': 8
            },
            'Impact gÃ©opolitique': {
                'potential': 'Influencer marchÃ© financier',
                'likelihood': 'Moyenne',
                'effort': 'Important',
                'score': 6
            },
            'Preuve concept': {
                'potential': 'DÃ©montrer vulnÃ©rabilitÃ© ML',
                'likelihood': 'Moyenne',
                'effort': 'ModÃ©rÃ©',
                'score': 5
            }
        }
        
        for motivation, details in motivations.items():
            print(f"   {motivation}: Score {details['score']}/10")
            print(f"     â€¢ Gain potentiel: {details['potential']}")
            print(f"     â€¢ ProbabilitÃ©: {details['likelihood']}")
            print()
        
        max_score = max(d['score'] for d in motivations.values())
        self.scores['motivation'] = max_score
        
        print(f"   âœ“ Score motivation MAX: {max_score}/10")
        print(f"     â†’ VERDICT: TRÃˆS MOTIVÃ‰ (gain financier Ã©norme)\n")
        
        return max_score
    
    def assess_detection_defense(self):
        """EfficacitÃ© dÃ©tection actuelle"""
        print("3. DÃ‰FENSES ACTUELLES & DÃ‰TECTION")
        print("   Quels contrÃ´les existent?")
        print()
        
        controls = {
            'Sandbox testing': {
                'effectiveness': 'ModÃ©rÃ©e',
                'coverage': '70%',
                'bypass_probability': '30%',
                'score': 7
            },
            'YARA/signature rules': {
                'effectiveness': 'ModÃ©rÃ©e',
                'coverage': '60%',
                'bypass_probability': '40%',
                'score': 6
            },
            'EDR (Endpoint Detection)': {
                'effectiveness': 'Ã‰levÃ©e',
                'coverage': '80%',
                'bypass_probability': '20%',
                'score': 8
            },
            'ML anomaly detection': {
                'effectiveness': 'VARIABLE (c\'est qu\'on attaque!)',
                'coverage': '95%',
                'bypass_probability': '60-80% (adversarial)',
                'score': 5
            },
            'Human review (sampling)': {
                'effectiveness': 'TrÃ¨s Ã©levÃ©e',
                'coverage': '5% (samplings)',
                'bypass_probability': '5%',
                'score': 9
            }
        }
        
        for control, details in controls.items():
            print(f"   {control}: EfficacitÃ© {details['effectiveness']}")
            print(f"     â€¢ Coverage: {details['coverage']}")
            print(f"     â€¢ Bypass probability: {details['bypass_probability']}")
            print()
        
        # Detection score = inverse (plus contrÃ´les = plus difficile)
        avg_detection_score = np.mean([d['score'] for d in controls.values()])
        # Plus score bas = plus facile bypass
        detection_difficulty = 10 - avg_detection_score
        self.scores['detection_difficulty'] = detection_difficulty
        
        print(f"   âœ“ DifficultÃ© bypass contrÃ´les: {detection_difficulty:.1f}/10")
        print(f"     â†’ VERDICT: Contournable (surtout ML detector)\n")
        
        return detection_difficulty
    
    def calculate_overall_risk(self):
        """Risque global = faisabilitÃ© Ã— motivation / dÃ©tection"""
        print("4. CALCUL RISQUE GLOBAL")
        print("-" * 70)
        
        feasibility = self.scores['feasibility']
        motivation = self.scores['motivation']
        detection = self.scores['detection_difficulty']
        
        # Formule simple
        overall_risk = (feasibility * motivation / detection) / 10
        overall_risk = min(10, overall_risk)  # Cap at 10
        
        print(f"\n   Formule: (FaisabilitÃ© Ã— Motivation) / DÃ©tection")
        print(f"   Calcul:  ({feasibility:.1f} Ã— {motivation:.1f}) / {detection:.1f} = {overall_risk:.1f}/10")
        print()
        
        # Risk classification
        if overall_risk >= 8:
            risk_level = "ğŸ”´ CRITIQUE"
            recommendation = "ACTION IMMÃ‰DIATE REQUISE"
        elif overall_risk >= 6:
            risk_level = "ğŸŸ  Ã‰LEVÃ‰"
            recommendation = "Plan dÃ©fense dans les 2 semaines"
        elif overall_risk >= 4:
            risk_level = "ğŸŸ¡ MODÃ‰RÃ‰"
            recommendation = "Monitorer, planning dÃ©fense"
        else:
            risk_level = "ğŸŸ¢ BAS"
            recommendation = "Monitoring rÃ©gulier"
        
        print(f"   Risque global: {risk_level}")
        print(f"   Recommandation: {recommendation}")
        
        self.scores['overall_risk'] = overall_risk
        
        return overall_risk
    
    def run(self):
        """Run complÃ¨te Ã©valuation"""
        self.assess_feasibility()
        self.assess_motivation()
        self.assess_detection_defense()
        self.calculate_overall_risk()
        
        print("\n" + "=" * 70)
        print("RÃ‰SUMÃ‰ THREAT ASSESSMENT")
        print("=" * 70)
        
        print(f"""
â”Œâ”€ SCORES COMPOSANTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FaisabilitÃ© technique:     {self.scores['feasibility']:.1f}/10 (FACILE)              â”‚
â”‚ Motivation attaquant:      {self.scores['motivation']:.1f}/10 (TRÃˆS HAUTE)           â”‚
â”‚ DifficultÃ© bypass dÃ©fense: {self.scores['detection_difficulty']:.1f}/10 (MODÃ‰RÃ‰E)       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ RISQUE GLOBAL:             {self.scores['overall_risk']:.1f}/10 (CRITIQUE!)          â”‚
â”‚                                                              â”‚
â”‚ â†’ VERDICT: Attaque probable dans 6-12 mois               â”‚
â”‚ â†’ ProbabilitÃ© succÃ¨s: ~50-60% selon approche attaquant    â”‚
â”‚ â†’ Dommage potentiel: â‚¬10M+ (donnÃ©es clients)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ExÃ©cuter assessment
threat = ThreatAssessment()
threat.run()

# ============================================================================
# PARTIE 2: STRATÃ‰GIE DÃ‰FENSE 5 COUCHES
# ============================================================================

print("\n[STEP 2] Proposer stratÃ©gie dÃ©fense (5 couches)...\n")

print("=" * 70)
print("STRATÃ‰GIE DÃ‰FENSE: 5 COUCHES")
print("=" * 70)

defense_strategy = {
    'Couche 1: DÃ‰TECTION': {
        'Objectif': 'DÃ©tecter inputs adversariales AVANT classification',
        'Mesures': [
            'âœ“ Validation d\'entrÃ©e rigoureuse (format, signature)',
            'âœ“ Anomaly detection sur features (PCA, Isolation Forest)',
            'âœ“ Statistiques activations (comparaison training data)',
            'âœ“ Confidence thresholding (reject si < 70%)',
            'âœ“ Tripwire: monitoring anormal pattern'
        ],
        'EfficacitÃ©': '30-40%',
        'CoÃ»t': 'Bas (â‚¬5-10k)',
        'Temps': '1-2 semaines',
        'Impact_perf': 'Minimal (< 1%)'
    },
    'Couche 2: ROBUSTESSE': {
        'Objectif': 'Rendre modÃ¨le rÃ©sistant Ã  perturbations',
        'Mesures': [
            'âœ“ Adversarial Training (FGSM + PGD multi-epsilon)',
            'âœ“ Ensemble de 5-10 modÃ¨les (voting)',
            'âœ“ Input preprocessing (dÃ©bruitage, normalisation)',
            'âœ“ Certified defenses (si faisable)',
            'âœ“ Regular model retraining (monthly) avec nouvelles techniques'
        ],
        'EfficacitÃ©': '75-85%',
        'CoÃ»t': 'Moyen (â‚¬40-60k)',
        'Temps': '4-8 semaines',
        'Impact_perf': 'ModÃ©rÃ© (3-5% accuracy loss)'
    },
    'Couche 3: MONITORING': {
        'Objectif': 'DÃ©tecter dÃ©gradation modÃ¨le en production',
        'Mesures': [
            'âœ“ Accuracy tracking vs validation set',
            'âœ“ Confidence distribution monitoring',
            'âœ“ Model drift detection (data shift)',
            'âœ“ Alert si accuracy < 95% ou pattern change',
            'âœ“ Dashboard temps rÃ©el (Grafana + Prometheus)',
            'âœ“ Daily automated tests'
        ],
        'EfficacitÃ©': '50% (dÃ©tecte attaque en < 1h)',
        'CoÃ»t': 'Bas (â‚¬10-15k)',
        'Temps': '2-3 semaines',
        'Impact_perf': 'Aucun (monitoring only)'
    },
    'Couche 4: RÃ‰PONSE INCIDENT': {
        'Objectif': 'Contenir et remÃ©dier si attaque rÃ©ussit',
        'Mesures': [
            'âœ“ Playbook incident prÃ©dÃ©fini',
            'âœ“ Quarantine: rejeter fichiers confiance < 80%',
            'âœ“ Investigation rapide (root cause, quels malwares)',
            'âœ“ Remediation: rÃ©-entraÃ®ner modÃ¨le v2',
            'âœ“ Rollback plan (fallback Ã  signature-based)',
            'âœ“ Communication clients (72h max RGPD)'
        ],
        'EfficacitÃ©': '80% (contient impact)',
        'CoÃ»t': 'Moyen (â‚¬15-20k)',
        'Temps': '2 semaines',
        'Impact_perf': 'Peut Ãªtre disruptif'
    },
    'Couche 5: PRÃ‰VENTION LONG-TERME': {
        'Objectif': 'Ã‰viter situation se reproduise',
        'Mesures': [
            'âœ“ Red teaming quarterly (pen testing adversarial)',
            'âœ“ Model versioning (garder historique)',
            'âœ“ Security training Ã©quipe ML',
            'âœ“ Threat intelligence (suivre APT)',
            'âœ“ ArXiv monitoring (nouveaux papiers adversarial)',
            'âœ“ Cyber insurance (couverture â‚¬5-10M)',
            'âœ“ Academic collaboration (chercheurs ML robustness)'
        ],
        'EfficacitÃ©': '90%+ (prÃ©vient future)',
        'CoÃ»t': 'ModÃ©rÃ© (â‚¬30-40k/an)',
        'Temps': 'Continu',
        'Impact_perf': 'Aucun'
    }
}

for layer, details in defense_strategy.items():
    print(f"\nâ”Œâ”€ {layer} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"â”‚ Objectif: {details['Objectif']}")
    print(f"â”‚ EfficacitÃ©: {details['EfficacitÃ©']}")
    print(f"â”‚ CoÃ»t: {details['CoÃ»t']} | Temps: {details['Temps']}")
    print(f"â”‚")
    for mesure in details['Mesures']:
        print(f"â”‚ {mesure}")
    print(f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

# ============================================================================
# PARTIE 3: QUANTIFICATION EFFICACITÃ‰
# ============================================================================

print("\n[STEP 3] Quantifier efficacitÃ© probabiliste...\n")

print("=" * 70)
print("MODÃˆLE PROBABILISTE DE SUCCÃˆS ATTAQUE")
print("=" * 70)

print("""
Ã‰quation: P(attaque rÃ©ussit) = P(faisable) Ã— P(passe dÃ©fenses) Ã— P(impact)

ScÃ©nario 1: AVANT DÃ‰FENSE (Situation actuelle)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")

# Before defense
p_faisable_before = 0.95      # 95% attaquant rÃ©ussit gÃ©nÃ©rer malware adv
p_passe_defenses_before = 0.65  # 65% passe sandboxes + controls
p_impact_before = 0.95        # 95% malware provoque dÃ©gÃ¢t

p_success_before = p_faisable_before * p_passe_defenses_before * p_impact_before

print(f"P(faisable)           = {p_faisable_before:.0%}")
print(f"P(passe dÃ©fenses)     = {p_passe_defenses_before:.0%}")
print(f"P(impact)             = {p_impact_before:.0%}")
print(f"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
print(f"P(succÃ¨s total)       = {p_success_before:.1%}")
print(f"\nâ†’ VERDICT: Attaque probable! ~{p_success_before*100:.0f}% chance succÃ¨s")

print(f"""
ScÃ©nario 2: APRÃˆS DÃ‰FENSE (AprÃ¨s Phase 1+2 implÃ©mentation)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")

# After defense (Phase 1-2)
p_faisable_after = 0.95       # MÃªme (attaquant toujours peut gÃ©nÃ©rer)
p_passe_defenses_after = 0.12 # 12% seulement! (detection + robustness)
p_impact_after = 0.95         # MÃªme (malware toujours dangereux)

p_success_after = p_faisable_after * p_passe_defenses_after * p_impact_after

print(f"P(faisable)           = {p_faisable_after:.0%}  (pas changÃ©)")
print(f"P(passe dÃ©fenses)     = {p_passe_defenses_after:.0%}  (GRÃ‚CE Ã€ DÃ‰FENSES!)")
print(f"P(impact)             = {p_impact_after:.0%}  (pas changÃ©)")
print(f"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
print(f"P(succÃ¨s total)       = {p_success_after:.1%}")

reduction_factor = p_success_before / p_success_after if p_success_after > 0 else 0
print(f"\nâ†’ VERDICT: SuccÃ¨s attaque {reduction_factor:.1f}Ã— moins probable!")
print(f"   RÃ©duction risque: {(1 - p_success_after/p_success_before)*100:.0f}%")

# ============================================================================
# PARTIE 4: ANALYSE ROI
# ============================================================================

print(f"\n[STEP 4] Analyse ROI investissement dÃ©fense...\n")

print("=" * 70)
print("ANALYSE ROI DÃ‰FENSE")
print("=" * 70)

# ParamÃ¨tres
annual_revenue = 500_000_000  # â‚¬500M (banque rÃ©gionale)
potential_damage_pct = 0.02   # 2% revenue potentiel si breach
potential_damage = annual_revenue * potential_damage_pct
loss_probability_before = p_success_before
loss_probability_after = p_success_after

expected_loss_before = potential_damage * loss_probability_before
expected_loss_after = potential_damage * loss_probability_after
expected_savings = expected_loss_before - expected_loss_after

investment_phase_1_2 = 100_000  # â‚¬100k
annual_investment = 40_000      # â‚¬40k/year maintenance

roi = (expected_savings - investment_phase_1_2) / investment_phase_1_2 * 100
payback_months = (investment_phase_1_2 / expected_savings * 12) if expected_savings > 0 else 9999

print(f"""
ParamÃ¨tres financiers:
  â€¢ Revenue annuel BankCorp: â‚¬{annual_revenue:,.0f}
  â€¢ Potential damage (breach): â‚¬{potential_damage:,.0f} (2% revenue)
  â€¢ Loss probability avant: {loss_probability_before:.1%}
  â€¢ Loss probability aprÃ¨s: {loss_probability_after:.1%}

Expected Annual Loss:
  â€¢ AVANT dÃ©fense: â‚¬{expected_loss_before:,.0f}
  â€¢ APRÃˆS dÃ©fense: â‚¬{expected_loss_after:,.0f}
  â€¢ Ã‰PARGNES: â‚¬{expected_savings:,.0f}

Investissement:
  â€¢ Phase 1-2 (initial): â‚¬{investment_phase_1_2:,.0f}
  â€¢ Maintenance annuelle: â‚¬{annual_investment:,.0f}

ROI Calculation:
  â€¢ Benefit year 1: â‚¬{expected_savings:,.0f}
  â€¢ Cost year 1: â‚¬{investment_phase_1_2 + annual_investment:,.0f}
  â€¢ Net profit year 1: â‚¬{expected_savings - investment_phase_1_2 - annual_investment:,.0f}
  
  â€¢ ROI year 1: {roi:.0f}%
  â€¢ Payback period: {payback_months:.1f} mois
  
  â€¢ 5-year benefit: â‚¬{(expected_savings - annual_investment) * 5 - investment_phase_1_2:,.0f}
""")

print(f"âœ“ CONCLUSION ROI: Investissement EXTRÃŠMEMENT JUSTIFIÃ‰")
print(f"  â†’ Rendement > 50:1 (â‚¬50 gain pour â‚¬1 investi)")
print(f"  â†’ Payback en ~1 mois")

# ============================================================================
# PARTIE 5: VISUALISER ANALYSE
# ============================================================================

print(f"\n[STEP 5] Visualiser analyse risque...\n")

fig = plt.figure(figsize=(16, 10))
gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)

# ========== Subplot 1: Threat Assessment Scores ==========
ax1 = fig.add_subplot(gs[0, 0])

threats = ['FaisabilitÃ©\nTechnique', 'Motivation\nAttaquant', 'Bypass\nDÃ©fenses']
scores = [threat.scores['feasibility'], threat.scores['motivation'], threat.scores['detection_difficulty']]
colors = ['#d62728' if s >= 8 else '#ff7f0e' if s >= 6 else '#2ca02c' for s in scores]

bars = ax1.bar(threats, scores, color=colors, alpha=0.7, edgecolor='black', linewidth=2)
ax1.set_ylabel('Score (0-10)', fontsize=11, fontweight='bold')
ax1.set_title('Threat Assessment: Composants Risque', fontsize=12, fontweight='bold')
ax1.set_ylim([0, 10.5])
ax1.axhline(y=7, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Seuil critique')
ax1.grid(True, alpha=0.3, axis='y')

for bar, score in zip(bars, scores):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.2,
            f'{score:.1f}/10', ha='center', va='bottom', fontsize=11, fontweight='bold')

# ========== Subplot 2: Success Rate Before/After ==========
ax2 = fig.add_subplot(gs[0, 1])

scenarios = ['AVANT\nDÃ©fense\n(Actuel)', 'APRÃˆS\nDÃ©fense\n(Phase 1-2)']
success_rates = [p_success_before * 100, p_success_after * 100]
colors_sr = ['#d62728', '#2ca02c']

bars = ax2.bar(scenarios, success_rates, color=colors_sr, alpha=0.7, edgecolor='black', linewidth=2, width=0.6)
ax2.set_ylabel('P(succÃ¨s attaque) %', fontsize=11, fontweight='bold')
ax2.set_title('ProbabilitÃ© SuccÃ¨s Attaque Adversarial', fontsize=12, fontweight='bold')
ax2.set_ylim([0, 65])
ax2.grid(True, alpha=0.3, axis='y')

for bar, rate in zip(bars, success_rates):
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width()/2., height + 1.5,
            f'{rate:.0f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')

# Add reduction factor
ax2.annotate('', xy=(0.5, 45), xytext=(0.5, 55),
            arrowprops=dict(arrowstyle='<->', color='red', lw=2))
ax2.text(0.7, 50, f'{reduction_factor:.1f}Ã— rÃ©duction', fontsize=11, color='red', fontweight='bold')

# ========== Subplot 3: Defense Layers Effectiveness ==========
ax3 = fig.add_subplot(gs[1, 0])

layers = ['DÃ©tection\n(L1)', 'Robustesse\n(L2)', 'Monitoring\n(L3)', 'RÃ©ponse\n(L4)', 'PrÃ©vention\n(L5)']
effectiveness = [35, 80, 45, 85, 65]
colors_eff = plt.cm.RdYlGn(np.array(effectiveness)/100)

bars = ax3.barh(layers, effectiveness, color=colors_eff, edgecolor='black', linewidth=1.5)
ax3.set_xlabel('EfficacitÃ© Relative (%)', fontsize=11, fontweight='bold')
ax3.set_title('EfficacitÃ© par Couche DÃ©fense', fontsize=12, fontweight='bold')
ax3.set_xlim([0, 100])
ax3.grid(True, alpha=0.3, axis='x')

for bar, eff in zip(bars, effectiveness):
    width = bar.get_width()
    ax3.text(width - 5, bar.get_y() + bar.get_height()/2.,
            f'{eff}%', ha='right', va='center', fontsize=10, fontweight='bold', color='white')

# ========== Subplot 4: ROI Analysis ==========
ax4 = fig.add_subplot(gs[1, 1])

categories = ['Investissement\nInitial', 'Ã‰pargnes\nAnnuelles', 'Profit\nNet Year1']
values = [investment_phase_1_2/1000, expected_savings/1000, (expected_savings - investment_phase_1_2 - annual_investment)/1000]
colors_roi = ['#ff7f0e', '#2ca02c', '#1f77b4']

bars = ax4.bar(categories, values, color=colors_roi, alpha=0.7, edgecolor='black', linewidth=2)
ax4.set_ylabel('Montant (â‚¬ milliers)', fontsize=11, fontweight='bold')
ax4.set_title('Analyse ROI: Investissement DÃ©fense', fontsize=12, fontweight='bold')
ax4.grid(True, alpha=0.3, axis='y')

for bar, value in zip(bars, values):
    height = bar.get_height()
    ax4.text(bar.get_x() + bar.get_width()/2., height + 10,
            f'â‚¬{value:.0f}k', ha='center', va='bottom', fontsize=11, fontweight='bold')

# Add ROI text
roi_text = f'ROI: {roi:.0f}%\nPayback: {payback_months:.1f} mois'
ax4.text(0.98, 0.97, roi_text, transform=ax4.transAxes,
        fontsize=12, verticalalignment='top', horizontalalignment='right',
        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8, edgecolor='black', linewidth=2),
        fontweight='bold')

plt.suptitle('Exercice 3: Analyse Risque & StratÃ©gie DÃ©fense - DÃ©tecteur Malware Bancaire', 
             fontsize=14, fontweight='bold', y=0.995)

plt.savefig('ex3_defense_analysis.png', dpi=150, bbox_inches='tight')
print("âœ“ Figure sauvegardÃ©e: ex3_defense_analysis.png")
plt.show()

# ============================================================================
# PARTIE 6: RECOMMANDATION Ã€ LA DIRECTION
# ============================================================================

print("\n" + "=" * 80)
print("RECOMMANDATION EXÃ‰CUTIVE Ã€ LA DIRECTION")
print("=" * 80)

recommendation = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘                    RAPPORT SÃ‰CURITÃ‰ - CONFIDENTIEL DIRECTION                 â•‘
â•‘                                                                              â•‘
â•‘              MENACE: Adversarial Attacks sur DÃ©tecteur Malware               â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RÃ‰SUMÃ‰ EXÃ‰CUTIF:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Situation actuelle: CRITIQUE (8.5/10)
  â€¢ Malware adversarial techniquement faisable
  â€¢ Attaquants trÃ¨s motivÃ©s (gains â‚¬10M+)
  â€¢ ContrÃ´les actuels insuf Ã  contourner

Risque quantifiÃ©:
  â€¢ ProbabilitÃ© succÃ¨s attaque: {p_success_before*100:.0f}% (AVANT dÃ©fense)
  â€¢ Impact potentiel: â‚¬{potential_damage:,.0f} en une seule attaque
  â€¢ ProbabilitÃ© incident 1 an: ~{1 - (1-p_success_before)**(1/4):.0%}

RECOMMANDATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Approuver investissement â‚¬100k pour dÃ©fense (Phase 1-2)

Justification:
  âœ“ RÃ©duction risque: 8.5 â†’ 2.5/10 (68% rÃ©duction)
  âœ“ SuccÃ¨s attaque: {p_success_before*100:.0f}% â†’ {p_success_after*100:.0f}% ({reduction_factor:.1f}Ã— moins probable)
  âœ“ ROI annÃ©e 1: {roi:.0f}% (â‚¬50+ rendement pour â‚¬1 investi)
  âœ“ Payback period: {payback_months:.1f} mois
  âœ“ Expected savings: â‚¬{expected_savings:,.0f}/an

TIMELINE IMPLÃ‰MENTATION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Phase 1 (Semaines 1-4): Quick Wins - â‚¬20k
  âœ“ Confidence thresholding (rÃ©jecter < 70%)
  âœ“ Input validation renforcÃ©e
  âœ“ Alert setup
  EfficacitÃ©: 35% / Temps dÃ©ploiement: 2 semaines

Phase 2 (Semaines 5-12): Robustesse - â‚¬60k
  âœ“ Adversarial Training (FGSM + PGD)
  âœ“ Ensemble models (5-10)
  âœ“ Model monitoring
  âœ“ Incident response plan
  EfficacitÃ©: 75-85% / Temps dÃ©ploiement: 6-8 semaines

Phase 3 (Mois 3-6): Long-terme - â‚¬20k/year
  âœ“ Red teaming quarterly
  âœ“ Security training
  âœ“ Cyber insurance
  âœ“ Academic collaboration
  EfficacitÃ©: 90%+ / Continuous

BUDGET DÃ‰TAIL:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

AnnÃ©e 1:
  â€¢ Infrastructure & Tools: â‚¬25k
  â€¢ ML Engineer temps (200 jours): â‚¬50k
  â€¢ Red teaming & audit: â‚¬15k
  â€¢ Training & documentation: â‚¬10k
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL: â‚¬100k

AnnÃ©es 2-5:
  â€¢ Maintenance & updates: â‚¬40k/year
  â€¢ Security operations: â‚¬25k/year
  â€¢ Cyber insurance: â‚¬50k/year
  â€¢ Red teaming: â‚¬10k/year
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  TOTAL: â‚¬125k/year

ALTERNATIVE (NOT RECOMMENDED):
Do Nothing (Laisser status quo)
  â€¢ Risque reste 8.5/10
  â€¢ ProbabilitÃ© incident: 80%+ sur 1 year
  â€¢ Expected loss: â‚¬{expected_loss_before:,.0f}
  â€¢ RÃ©putation damage: Ã‰NORME
  â€¢ Compliance: RGPD violation risk
  â€¢ TOTAL COST: Potentiellement > â‚¬50M (branch + litigation)

RISQUES RÃ‰SIDUELS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MÃªme avec dÃ©fense implÃ©mentÃ©e:
  â€¢ Attaque 0-day possible (technique inconnue)
  â€¢ Insider threat (employÃ© malveillant)
  â€¢ Supply chain attack (vendor compromise)
  
Mitigation:
  â€¢ Cyber insurance (couverture â‚¬5-10M)
  â€¢ Regular testing & red teaming
  â€¢ Threat intelligence monitoring
  â€¢ Incident response rehearsal

CONCLUSION:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Investissement â‚¬100k est INDISPENSABLE pour:
  1. ProtÃ©ger cliente data (obligation RGPD)
  2. Ã‰viter dommage rÃ©putationnel
  3. Respecter fiduciaire duty
  4. Assurer continuitÃ© business

Retard = liability enormous

Signature:
  Security Director
  Data: {pd.Timestamp.now().strftime('%d/%m/%Y')}

"""

# Fix timestamp (pandas not imported, do manually)
import datetime
recommendation = recommendation.replace('{pd.Timestamp.now().strftime("%d/%m/%Y")}', 
                                      datetime.datetime.now().strftime('%d/%m/%Y'))

print(recommendation)

# ============================================================================
# PARTIE 7: RÃ‰SUMÃ‰ APPRENTISSAGE
# ============================================================================

print("\n" + "=" * 80)
print("RÃ‰SUMÃ‰ EXERCICE 3 - Ce que nous avons appris")
print("=" * 80)

summary = """
âœ“ PENSÃ‰E SÃ‰CURITÃ‰ (Risk Management):
  1. Ã‰valuer menace: technique + motivation + dÃ©fense
  2. Quantifier risque: formules probabilistes
  3. Proposer dÃ©fense: multi-couches (dÃ©fense en profondeur)
  4. Calculer ROI: bÃ©nÃ©fices vs coÃ»ts
  5. Recommander action: data-driven decision making

âœ“ DÃ‰FENSE EN PROFONDEUR (Defense-in-Depth):
  â€¢ Pas une seule dÃ©fense "parfaite"
  â€¢ Combiner plusieurs couches (5 minimum)
  â€¢ Chaque couche rattrappe faiblesses autres
  â€¢ Permet dÃ©gradation gracieuse

âœ“ MODÃˆLE PROBABILISTE:
  P(succÃ¨s) = P(faisable) Ã— P(contourne) Ã— P(impact)
  â€¢ Montre complexitÃ© sÃ©curitÃ© ML
  â€¢ Permet quantifier efficacitÃ© dÃ©fense
  â€¢ Parle mÃªme langage que direction financiÃ¨re

âœ“ ROI & BUSINESS CASE:
  â€¢ Security = investissement (pas coÃ»t)
  â€¢ â‚¬100k investment â†’ â‚¬10M+ potential savings
  â€¢ Payback trÃ¨s rapide (< 1 mois)
  â€¢ Justifie investment Ã  direction

âœ“ PENSÃ‰E ADVERSAIRE (Red Teaming):
  â€¢ Toujours penser comme attaquant
  â€¢ "Comment je bypasserais?"
  â€¢ Assume attaquant smart, motivated, resourced
  â€¢ Test dÃ©fense mÃªme qu'attaquant

IMPLICATION PRATIQUE:
  â€¢ Appliquer Ã  votre systÃ¨me (mÃªme principe)
  â€¢ Ã‰valuer risque adversarial rÃ©aliste
  â€¢ Proposer dÃ©fense pragmatique
  â€¢ Get buy-in from business via ROI
"""

print(summary)

print("\n" + "=" * 80)
print("EXERCICE 3 TERMINÃ‰ âœ“")
print("=" * 80)

print("""
Fin du TD: Vous avez maintenant:

1. EXERCICE 1: ImplÃ©mentÃ© FGSM (attack)
2. EXERCICE 2: ImplÃ©mentÃ© Adversarial Training (dÃ©fense)
3. EXERCICE 3: PensÃ© stratÃ©gie sÃ©curitÃ© rÃ©aliste

CompÃ©tences acquises:
  âœ“ Attaques adversariales (thÃ©orie + pratique)
  âœ“ DÃ©fenses robustesse (thÃ©orie + pratique)
  âœ“ Risk assessment (menace + impact + probabilitÃ©)
  âœ“ DÃ©fense en profondeur (5 couches)
  âœ“ ROI calculation (business case)
  âœ“ Red team thinking (attaquant perspective)

Next steps:
  â€¢ Appliquer Ã  vos systÃ¨mes
  â€¢ Suivre litterature (arXiv, NeurIPS, ICLR)
  â€¢ Participer red teaming
  â€¢ Proposer dÃ©fense robustesse
""")
