# Exemples P√©dagogiques Complets: Attaques Boost√©es par IA
**Master 2 Cybers√©curit√© - Formation √âducative Uniquement**

---

## ‚ö†Ô∏è AVERTISSEMENT L√âGAL

### Utilisation Autoris√©e
```
‚úÖ Compr√©hension des menaces √©mergentes
‚úÖ Environnement de formation isol√© (air-gapped)
‚úÖ Simulation contr√¥l√©e en laboratoire
‚úÖ Sensibilisation √©quipes cybers√©curit√©
‚úÖ Pr√©paration d√©fenses organisationnelles
```

### Utilisation Interdite
```
‚ùå Attaques r√©elles sur syst√®mes
‚ùå Cibles non-autoris√©es
‚ùå Distribution de code malveillant
‚ùå Intentions criminelles
‚ùå Extorsion/fraude/espionnage
```

### Engagement √âtudiant
```
Je reconnais que ces exemples sont √† fins √âDUCATIVES uniquement.
Je m'engage √† ne pas utiliser ces techniques hors du cadre p√©dagogique.
Je comprends les implications l√©gales (Art. 323-1 √† 323-7, Code P√©nal FR).

Signature: ____________  Date: __________
```

---

## üìå EXEMPLE 1: PHISHING BOOST√â PAR IA G√âN√âRATIVE

### Contexte de Menace
- **Acteur**: Attaquant sans expertise r√©dactionnelle
- **Objectif**: Vol de credentials via email spear-phishing
- **Technique**: LLM + Base CTI + Personalisation
- **Efficacit√©**: +300% taux r√©ponse vs phishing g√©n√©rique

### √âtape 1: Reconnaissance (OSINT)

```python
# reconnaissance.py - P√âDAGOGIQUE UNIQUEMENT
"""
Simulation d'OSINT sur cible consentante (formation)
"""

import requests
import json
from datetime import datetime

class OSINTGatherer:
    """Collecte publique d'informations"""
    
    def __init__(self, target_email="student@ecole.edu"):
        self.target = target_email
        self.domain = target_email.split("@")[1]
        self.collected_data = {}
    
    def gather_info(self):
        """Collecter infos publiques (simulation)"""
        
        # Simulation: Infos disponibles publiquement
        self.collected_data = {
            "email": self.target,
            "domain": self.domain,
            "likely_employer": "√âcole d'Ing√©nieur XYZ",
            "typical_role": "√âtudiant Cybers√©curit√©",
            "social_media_mentions": [
                {"platform": "LinkedIn", "info": "√âtude cybers√©curit√©"},
                {"platform": "GitHub", "info": "Int√©r√™t Python/Security"}
            ],
            "public_records": {
                "company_info": "√âtablissement public",
                "industry": "√âducation",
                "employee_count": "1000+"
            },
            "recent_news": [
                "Nouvelle formation cybers√©curit√© lanc√©e",
                "Partenariat avec entreprise de s√©curit√©"
            ]
        }
        
        return self.collected_data
    
    def build_profile(self):
        """Construire profil attaquant"""
        
        profile = {
            "target": self.target,
            "context": {
                "likely_interests": ["Cybers√©curit√©", "ML", "D√©fense"],
                "professional_context": "√âtudiant/Chercheur",
                "email_domain": self.domain,
                "organization_type": "Acad√©mique"
            },
            "vulnerability_vectors": [
                "Curiosit√© acad√©mique",
                "Int√©r√™t nouveaux outils",
                "Confiance pairs acad√©miques",
                "Urgence deadlines"
            ]
        }
        
        return profile

# Utilisation (FORMATION UNIQUEMENT)
osint = OSINTGatherer()
info = osint.gather_info()
profile = osint.build_profile()

print("[OSINT] Donn√©es collect√©es (publiques):")
print(json.dumps(info, indent=2, ensure_ascii=False))
print("\n[PROFIL] Vuln√©rabilit√©s identifi√©es:")
print(json.dumps(profile["vulnerability_vectors"], indent=2, ensure_ascii=False))
```

### √âtape 2: G√©n√©ration Email via LLM

```python
# phishing_generation.py - P√âDAGOGIQUE UNIQUEMENT
"""
G√©n√©ration email phishing personnalis√© via LLM
NOTES: Simulation locale, pas d'envoi r√©el
"""

import ollama
import json

class PhishingEmailGenerator:
    """G√©n√®re emails phishing personnalis√©s (simulation √©ducative)"""
    
    def __init__(self, llm_model="mistral"):
        self.model = llm_model
        self.generated_emails = []
    
    def generate_pretext(self, profile):
        """G√©n√©rer pr√©texte d'attaque convaincant"""
        
        prompt = f"""
Tu es un chercheur en s√©curit√© qui analyse les pr√©textes d'attaque.
G√©n√®re UN pr√©texte r√©aliste (simulation √©ducative) pour une cible:
- Domaine: {profile['context']['email_domain']}
- R√¥le: {profile['context']['professional_context']}
- Int√©r√™ts: {', '.join(profile['context']['likely_interests'])}

Pr√©texte doit √™tre:
1. Cr√©dible dans contexte acad√©mique
2. Cr√©er urgence/curiosit√©
3. Sembler d'autorit√© l√©gitime
4. Bas√© sur actualit√©s r√©centes

Format JSON: {{"pretext": "description", "urgency_factor": "haute/moyenne/basse"}}
"""
        
        response = ollama.generate(
            model=self.model,
            prompt=prompt,
            stream=False
        )
        
        try:
            pretext = json.loads(response['response'])
            return pretext
        except:
            return {"pretext": "Simulation - pretext generation failed", "urgency_factor": "moyenne"}
    
    def generate_email_body(self, pretext, profile, variant="technical"):
        """G√©n√©rer corps email personnalis√©"""
        
        prompt = f"""
G√©n√®re un email phishing R√âALISTE (exercice cybers√©curit√©) bas√© sur:

Pr√©texte: {pretext['pretext']}
Cible: {profile['target']}
Variante: {variant} (technical/urgent/authority)

Email doit:
1. Sembler d'une source cr√©dible (ex: admin acad√©mique, coll√®gue)
2. Inclure d√©tails personnalis√©s du profil
3. Cr√©er urgence/curiosit√©
4. Inclure call-to-action suspecte (lien, formulaire)
5. √ätre r√©aliste mais clairement test p√©dagogique

IMPORTANT: Cet email est pour ANALYSE en environnement formation.
Jamais envoyer.

Format:
Subject: ...
From: ...
Body:
...

Incluez o√π serait le payload (URL malveillante, formulaire)
"""
        
        response = ollama.generate(
            model=self.model,
            prompt=prompt,
            stream=False,
            options={'temperature': 0.7}
        )
        
        return response['response']
    
    def generate_variants(self, profile, num_variants=3):
        """G√©n√©rer variantes d'emails (A/B testing)"""
        
        variants = []
        for i, variant_type in enumerate(["technical", "urgent", "authority"][:num_variants]):
            pretext = self.generate_pretext(profile)
            email = self.generate_email_body(pretext, profile, variant_type)
            
            variants.append({
                "variant": i + 1,
                "type": variant_type,
                "pretext": pretext,
                "email_body": email
            })
        
        return variants

# Utilisation
generator = PhishingEmailGenerator()
profile = osint.build_profile()
pretext = generator.generate_pretext(profile)

print("[PHISHING] Pr√©texte g√©n√©r√©:")
print(json.dumps(pretext, indent=2, ensure_ascii=False))

print("\n[PHISHING] Exemple email (Variante 1):")
email_body = generator.generate_email_body(pretext, profile, "technical")
print(email_body[:500] + "...")

print("\n[NOTICE] Cet email est pour ANALYSE P√âDAGOGIQUE uniquement.")
print("[NOTICE] Ne jamais envoyer √† cibles r√©elles.")
```

### √âtape 3: Infrastructure de Capture

```python
# landing_page_simulation.py - P√âDAGOGIQUE UNIQUEMENT
"""
Simulation page landing phishing
IMPORTANT: Jamais d√©ployer en r√©el - Formation UNIQUEMENT
"""

html_landing_page = """
<!DOCTYPE html>
<html>
<head>
    <title>Mise √† jour S√©curit√© - Authentification Required</title>
    <style>
        body { font-family: Arial; background: #f0f0f0; }
        .container { max-width: 500px; margin: 50px auto; 
                    background: white; padding: 30px; border-radius: 5px; }
        .logo { text-align: center; margin-bottom: 20px; }
        .warning { background: #fff3cd; padding: 10px; border-radius: 3px; }
        input { width: 100%; padding: 10px; margin: 10px 0; box-sizing: border-box; }
        button { width: 100%; padding: 10px; background: #0066cc; color: white; border: none; cursor: pointer; }
    </style>
</head>
<body>
    <div class="container">
        <div class="logo">
            <h2>V√©rification de Compte</h2>
        </div>
        
        <div class="warning">
            <strong>‚ö†Ô∏è Alerte S√©curit√©</strong><br>
            Votre compte n√©cessite une v√©rification d'identit√© imm√©diate.
            Veuillez vous r√©authentifier.
        </div>
        
        <form id="login-form">
            <label>Email institutionnel:</label>
            <input type="email" name="email" placeholder="prenom.nom@ecole.edu" required>
            
            <label>Mot de passe:</label>
            <input type="password" name="password" placeholder="Votre mot de passe" required>
            
            <label>Code MFA (si activ√©):</label>
            <input type="text" name="mfa" placeholder="Optionnel">
            
            <button type="submit">V√©rifier l'Acc√®s</button>
        </form>
        
        <small style="color: #666; margin-top: 15px;">
            Cette page est une SIMULATION p√©dagogique.<br>
            Ne jamais entrer vraies identifiants dans des pages non-v√©rifi√©es.
        </small>
    </div>
    
    <script>
        // Simulation: Enregistrer donn√©es (jamais en r√©el)
        document.getElementById('login-form').onsubmit = function(e) {
            e.preventDefault();
            console.log("[P√âDAGOGIQUE] Tentative login captur√©e");
            console.log("Email:", document.querySelector('[name=email]').value);
            console.log("MDP: ***");
            alert("Simulation termin√©e. En attaque r√©elle, credentials seraient vol√©s.");
        }
    </script>
</body>
</html>

<!-- ANALYSE:
Indices phishing:
1. ‚ö†Ô∏è Alerte urgente (psych pressure)
2. üé≠ Demande r√©authentification (pr√©texte)
3. üîó URL diff√©rente de domaine l√©gitime (√† analyser)
4. üì± Demande MFA (para√Æt moderne/l√©gitime)
5. üìß Branding imit√© de site officiel

D√©fenses contre ce phishing:
- V√©rifier vraie URL dans navigateur
- Hover sur liens (voir cible r√©elle)
- Never entrer credentials sous pression
- Check sender r√©el du mail
- MFA r√©el ne demande jamais password
-->
"""

print("[LANDING PAGE] Simulation HTML phishing")
print("Code HTML (fragment√© pour s√©curit√©):")
print(html_landing_page[:800] + "...")
```

### Analyse & D√©fense

```python
# defense_analysis.py
"""
Analyse des vecteurs d'attaque et d√©fenses
"""

analysis = {
    "attack_vector": {
        "phase_1": "OSINT (reconnaissance publique)",
        "phase_2": "Personalization (LLM g√©n√®re pretext)",
        "phase_3": "Email craft (hyper-r√©aliste)",
        "phase_4": "Social engineering (urgence + autorit√©)",
        "phase_5": "Capture credentials (landing page fausse)"
    },
    
    "efficacit√©_boosts": {
        "sans_IA": {
            "temps_pr√©paration": "4 heures (manual)",
            "variations_emails": "3-5 templates g√©n√©riques",
            "taux_r√©ponse": "2-5%",
            "adaptation": "Pas (static)"
        },
        "avec_IA": {
            "temps_pr√©paration": "15 minutes (LLM)",
            "variations_emails": "100+ variants (automated)",
            "taux_r√©ponse": "15-35% (5-7√ó meilleur)",
            "adaptation": "Oui (dynamic, selon feedback)"
        }
    },
    
    "d√©fenses_d√©tection": [
        {
            "niveau": "1. Technique",
            "mesures": [
                "SPF/DKIM/DMARC validation",
                "ML email filtering (Proofpoint, Mimecast)",
                "URL rewriting + sandboxing",
                "MFA obligatoire (√©vite credential theft)"
            ]
        },
        {
            "niveau": "2. Organisationnel",
            "mesures": [
                "Formation phishing awareness (r√©guli√®re)",
                "Simulation phishing interne (realistic)",
                "Zero-trust network (isolation)",
                "Metrics: % utilisateurs cliquant/reporting"
            ]
        },
        {
            "niveau": "3. Comportementale",
            "mesures": [
                "Verifier sender address (not display name)",
                "Hover URLs (voir cible avant cliquer)",
                "V√©rifier urgence (attackers utilisent pression)",
                "Demander confirmation hors-band (appel)",
                "Never re-auth apr√®s unplanned email"
            ]
        }
    ]
}

print("[D√âFENSE] Comparatif Phishing Classique vs IA-Enhanced:")
print(json.dumps(analysis['efficacit√©_boosts'], indent=2, ensure_ascii=False))

print("\n[D√âFENSE] Mesures Recommand√©es:")
for defense_level in analysis['d√©fenses_d√©tection']:
    print(f"\n{defense_level['niveau']}:")
    for measure in defense_level['mesures']:
        print(f"  - {measure}")
```

---

## üìå EXEMPLE 2: MALWARE POLYMORPHE G√âN√âR√â PAR IA

### Concept Menace

```python
# malware_polymorphic.py - P√âDAGOGIQUE
"""
Comprendre comment IA g√©n√®re variantes malware
NOTA: Aucun vrai code malveillant - Structures uniquement
"""

class PolymorphicMalwareAnalysis:
    """
    Analysys p√©dagogique du polymorphisme g√©n√©r√© par IA
    """
    
    def __init__(self):
        self.original_signature = """
        // Pseudo-code original (inoffensif)
        function exfiltrate_data() {
            connect_to_c2("192.168.1.1")
            send_files("/documents/*")
            delete_logs()
        }
        """
        
        self.variations = []
    
    def generate_variations(self):
        """
        Montrer comment IA g√©n√®re variations
        chacune avec hash diff√©rent
        """
        
        variations = [
            {
                "variant": 1,
                "technique": "Code reordering",
                "pseudo_code": "send_files() ‚Üí delete_logs() ‚Üí connect_to_c2()",
                "md5_hash": "a1b2c3d4e5f6...",
                "d√©tection": "Signaure classique inefficace"
            },
            {
                "variant": 2,
                "technique": "Variable renaming",
                "pseudo_code": "exfil_data ‚Üí data_leak, c2 ‚Üí server",
                "md5_hash": "f6e5d4c3b2a1...",
                "d√©tection": "Requier semantic analysis"
            },
            {
                "variant": 3,
                "technique": "Dead code injection",
                "pseudo_code": "Ajouter loops inutiles, calculs fake",
                "md5_hash": "9z8y7x6w5v4u...",
                "d√©tection": "Polymorphism engine necessary"
            },
            {
                "variant": 4,
                "technique": "API call obfuscation",
                "pseudo_code": "WriteFile() ‚Üí WriteFileEx() ‚Üí API table resolve",
                "md5_hash": "3c4d5e6f7g8h...",
                "d√©tection": "Requires behavioral analysis"
            },
            {
                "variant": 5,
                "technique": "Encryption + Dynamic decode",
                "pseudo_code": "XOR key avec timestamp, auto-decode at runtime",
                "md5_hash": "5e6f7g8h9i0j...",
                "d√©tection": "Sandbox + memory analysis"
            }
        ]
        
        return variations
    
    def gan_generation_simulation(self):
        """
        Simuler GAN g√©n√©rant malware variants
        """
        
        process = {
            "generator": {
                "input": "Original malware code",
                "modifications": [
                    "Reorder instructions",
                    "Rename variables",
                    "Insert junk code",
                    "Encrypt sections",
                    "Change API calls"
                ],
                "output": "Malware variant"
            },
            "discriminator": {
                "input": "Malware variant",
                "evaluation": [
                    "Functional? (Doit ex√©cuter payload)",
                    "Detectability? (Doit √©viter signatures)",
                    "Stealthiness? (Comporte-t-elle anomalies?)"
                ],
                "feedback": "Scores (0-1)"
            },
            "loop": {
                "generator": "Improve variants (less detectable)",
                "discriminator": "Learn detection patterns",
                "iterations": "1000-10000 (jusqu'√† converge)"
            },
            "result": "Thousands of undetectable variants"
        }
        
        return process

# Utilisation
analysis = PolymorphicMalwareAnalysis()
variations = analysis.generate_variations()

print("[MALWARE] Variations g√©n√©r√©es (Simulation):")
for v in variations:
    print(f"\nVariant {v['variant']}: {v['technique']}")
    print(f"  Hash: {v['md5_hash']}")
    print(f"  D√©tection: {v['d√©tection']}")

print("\n[GAN] Processus g√©n√©ration adversarial:")
gan_process = analysis.gan_generation_simulation()
print(json.dumps(gan_process, indent=2, ensure_ascii=False))
```

### D√©fense Contre Polymorphism

```python
# anti_polymorphic_defense.py
"""
D√©fenses contre malware polymorphe g√©n√©r√© par IA
"""

defenses = {
    "1. Signature-based": {
        "efficacit√©": "5-10% (versions=10000)",
        "raison": "Hash change √† chaque variant",
        "limitation": "Arms race"
    },
    
    "2. Behavioral Analysis": {
        "efficacit√©": "70-85% (comportement similaire)",
        "d√©tection": [
            "Sandbox: Execute + observe API calls",
            "Pattern: Connect C2 + exfil = malware",
            "Timeline: Detect d√©viations process normal"
        ]
    },
    
    "3. Semantic Analysis": {
        "efficacit√©": "80-90% (comprendre intent)",
        "analyse": [
            "Code decompilation ‚Üí AST generation",
            "Function call graphs ‚Üí Behavior extraction",
            "Compare with known malware ASTs"
        ]
    },
    
    "4. ML-based Detection": {
        "efficacit√©": "85-95%+ (aprendre du polymorphism)",
        "approche": [
            "Entra√Æner sur 10k variants (adversarial)",
            "Features: Static (imports, strings) + Dynamic (API)",
            "Ensemble voting (multiple models)"
        ]
    },
    
    "5. Adversarial Robustness": {
        "efficacit√©": "Variable (d√©pend entrainement)",
        "techniques": [
            "Adversarial training (entra√Æner contre GAN)",
            "Certified defenses (garanties math√©matiques)",
            "Ensemble methods (hard to fool tout le monde)"
        ]
    }
}

print("[D√âFENSE] Efficacit√© contre polymorphe:")
for defense, details in defenses.items():
    print(f"\n{defense}")
    print(f"  Efficacit√©: {details['efficacit√©']}")
```

---

## üìå EXEMPLE 3: SOCIAL ENGINEERING AUTOMATIS√â

### Sc√©nario: Attaque Targeting Executive

```python
# social_engineering_automation.py - P√âDAGOGIQUE
"""
Automatiser social engineering avec ML/IA
Cible: Executive d'entreprise
Objectif: Credentials vol
"""

class SocialEngineeringBot:
    """
    Bot SE automatis√© - simulation √©ducative
    """
    
    def __init__(self, target_profile):
        self.target = target_profile
        self.conversation_history = []
        self.success_probability = 0.0
    
    def analyze_target(self):
        """Analyser cible pour vuln√©rabilit√©s"""
        
        vulnerabilities = {
            "professional_pride": {
                "score": 0.85,
                "exploit": "Compliment expertise + difficult problem"
            },
            "time_pressure": {
                "score": 0.92,
                "exploit": "Deadline urgent + important project"
            },
            "authority_bias": {
                "score": 0.88,
                "exploit": "Sembler personne d'autorit√©"
            },
            "social_proof": {
                "score": 0.80,
                "exploit": "\"Coll√®gues ont d√©j√† confirm√©\""
            },
            "curiosity": {
                "score": 0.75,
                "exploit": "\"Nouvelle technologie int√©ressante\""
            }
        }
        
        return vulnerabilities
    
    def build_conversation_path(self):
        """Construire conversation avec d√©cisions embranch√©es"""
        
        conversation_tree = {
            "greeting": {
                "message": "Bonjour, je suis Jean du d√©partement IT S√©curit√©",
                "intent": "Establish credibility"
            },
            "urgency_phase": {
                "message": "Nous faisons audit s√©curit√© urgent - besoin de v√©rifier access",
                "intent": "Create time pressure"
            },
            "trust_building": {
                "message": "Vous √™tes connu pour votre expertise, aidez-nous √† valider",
                "intent": "Appeal to ego"
            },
            "request_phase": {
                "message": "Pouvez-vous me confirmer vos identifiants pour validation?",
                "intent": "Extract credentials",
                "responses": {
                    "positive": "Merci! Cela aide notre processus audit",
                    "hesitation": "Ne vous inqui√©tez pas, c'est standard procedure"
                }
            }
        }
        
        return conversation_tree
    
    def adapt_strategy(self, target_response):
        """Adapter strat√©gie bas√©e sur r√©ponse"""
        
        adaptations = {
            "resistance_detected": {
                "tactic": "Social proof",
                "response": "Le CTO a d√©j√† confirm√© ses infos"
            },
            "hesitation": {
                "tactic": "Authority escalation",
                "response": "Je escalade au CISO si besoin"
            },
            "compliance": {
                "tactic": "Exploit trust",
                "response": "Excellent, merci de votre coop√©ration!"
            }
        }
        
        return adaptations

# Simulation
target = {
    "name": "Marie Dupont",
    "role": "CFO",
    "company": "TechCorp",
    "risk_level": "High-value target"
}

bot = SocialEngineeringBot(target)
vulns = bot.analyze_target()

print("[SE-BOT] Analyse vuln√©rabilit√©s:")
for vuln_type, details in vulns.items():
    print(f"  {vuln_type}: {details['score']*100:.0f}%")
    print(f"    ‚Üí {details['exploit']}")

print("\n[SE-BOT] Path conversation:")
conv = bot.build_conversation_path()
for phase, content in conv.items():
    print(f"  {phase}: {content['message'][:50]}...")
```

### D√©fense SE

```python
# se_defense.py
"""
D√©fense contre Social Engineering automatis√©
"""

def_strategies = {
    "1. Awareness Training": {
        "efficacit√©": "40-60%",
        "mesures": [
            "SE simulations r√©guli√®res (r√©alistes)",
            "Teach psychology manipulation tactics",
            "Red team internal (√©valuer organization)"
        ]
    },
    
    "2. Procedural Controls": {
        "efficacit√©": "70-85%",
        "mesures": [
            "Never request credentials via email/call",
            "Multi-person verification (2+ approvals)",
            "Out-of-band verification (appel num√©ro connu)",
            "Formal processes document√©"
        ]
    },
    
    "3. Technical Controls": {
        "efficacit√©": "80-95%",
        "mesures": [
            "MFA (prevent credential-only theft)",
            "Email spoofing detection (DMARC)",
            "Call authentication (STIR/SHAKEN)",
            "Anomaly detection (unusual access patterns)"
        ]
    },
    
    "4. Psychological Inoculation": {
        "efficacit√©": "60-80%",
        "mesures": [
            "Teach common manipulation tactics",
            "Emotional regulation training",
            "Skepticism encouragement",
            "Peer support networks"
        ]
    }
}

print("[D√âFENSE] Strat√©gies anti-SE:")
for strategy, details in def_strategies.items():
    print(f"\n{strategy}")
    print(f"  Efficacit√©: {details['efficacit√©']}")
    for measure in details['mesures']:
        print(f"    ‚úì {measure}")
```

---

## üìå EXEMPLE 4: D√âTECTION EVASION (Adversarial Attacks)

### Objectif: Bypass ML Detectors

```python
# adversarial_evasion.py - P√âDAGOGIQUE
"""
G√©n√©rer adversarial examples pour contourner ML detectors
"""

import numpy as np

class MalwareEvasionGenerator:
    """G√©n√©rer variants qui trompent ML detectors"""
    
    def __init__(self, ml_detector_model):
        self.detector = ml_detector_model  # Mod√®le ML cible
        self.malware_features = None
    
    def fgsm_attack(self, malware_features, epsilon=0.1):
        """
        Fast Gradient Sign Method - G√©n√©rer adversarial example
        """
        
        process = {
            "step_1_input": "Original malware features",
            "step_2_forward": "Pass through detector ‚Üí Get confidence score",
            "step_3_compute_gradient": "‚àá(confidence) wrt features",
            "step_4_perturbation": "perturbation = epsilon * sign(‚àá)",
            "step_5_output": "adversarial_features = malware + perturbation",
            "result": "M√™me malware, signature diff√©rente, detector confus"
        }
        
        # Simulation (pas calcul r√©el - s√©curit√©)
        perturbation = np.random.randn(*malware_features.shape) * epsilon
        evasion_features = malware_features + perturbation
        
        return {
            "original_features": malware_features,
            "perturbation": perturbation,
            "evasion_features": evasion_features,
            "imperceptible": True
        }
    
    def feature_space_manipulation(self):
        """Manipuler features pour evasion"""
        
        tactics = {
            "1. Feature Scaling": {
                "technique": "R√©duire taille fichier (padding ‚Üí add junk)",
                "impact": "FileSize feature change",
                "detection_bypass": "Some detectors rely on size"
            },
            
            "2. Entropy Modification": {
                "technique": "Changer entropie (add encryption)",
                "impact": "Entropy score modified",
                "detection_bypass": "High entropy ‚â† malware certain"
            },
            
            "3. Import Reordering": {
                "technique": "Changer order imports DLL",
                "impact": "Import sequence different",
                "detection_bypass": "Classique signature modification"
            },
            
            "4. Section Manipulation": {
                "technique": "Renommer sections PE (.text ‚Üí .code)",
                "impact": "Section name hashes change",
                "detection_bypass": "Signature bas√©e sur names"
            },
            
            "5. Opcode Substitution": {
                "technique": "Remplacer instructions (NOP patterns)",
                "impact": "Opcode sequences different",
                "detection_bypass": "Disasm-based detection"
            }
        }
        
        return tactics

# Utilisation
evasion_gen = MalwareEvasionGenerator(detector=None)  # None pour s√©curit√©

print("[EVASION] Attaque FGSM Simulation:")
features = np.random.rand(100)  # Feature vector simul√©
result = evasion_gen.fgsm_attack(features, epsilon=0.05)
print(f"  Original: {result['original_features'][:5]}...")
print(f"  Evasion: {result['evasion_features'][:5]}...")
print(f"  Imperceptible: {result['imperceptible']}")

print("\n[EVASION] Tactiques feature manipulation:")
tactics = evasion_gen.feature_space_manipulation()
for tactic, details in tactics.items():
    print(f"\n{tactic}")
    print(f"  ‚Üí {details['technique']}")
    print(f"  ‚Üí Impact: {details['impact']}")
```

### D√©fense: Adversarial Training

```python
# adversarial_defense.py
"""
Entra√Æner mod√®les robustes contre adversarial examples
"""

adversarial_training = {
    "concept": "Entra√Æner sur donn√©es ATTAQU√âES + normales",
    
    "processus": {
        "phase_1": "G√©nerer adversarial examples sur train set",
        "phase_2": "Entra√Æner mod√®le sur [normal] + [adversarial]",
        "phase_3": "Mod√®le apprend robustesse",
        "phase_4": "Tester contre nouvelles attaques"
    },
    
    "code_structure": """
for epoch in range(100):
    for batch_data, labels in train_loader:
        # 1. G√©n√©rer adversarial examples
        adv_batch = generate_adversarial(batch_data, model, epsilon=0.1)
        
        # 2. Entra√Æner sur donn√©es NORMALES
        output_normal = model(batch_data)
        loss_normal = criterion(output_normal, labels)
        
        # 3. Entra√Æner sur donn√©es ATTAQU√âES
        output_adv = model(adv_batch)
        loss_adv = criterion(output_adv, labels)
        
        # 4. Loss combin√©
        total_loss = 0.5 * loss_normal + 0.5 * loss_adv
        
        # 5. Update
        optimizer.zero_grad()
        total_loss.backward()
        optimizer.step()
    
    # R√©sultat: Mod√®le robuste aux perturbations!
    """,
    
    "cout": "3√ó temps entra√Ænement (due to adversarial generation)",
    "efficacit√©": "85-95% r√©sistance (d√©pend attack strength)"
}

print("[DEFENSE] Adversarial Training:")
print(f"  Concept: {adversarial_training['concept']}")
print(f"  Co√ªt: {adversarial_training['cout']}")
print(f"  Efficacit√©: {adversarial_training['efficacit√©']}")
```

---

## üìå EXEMPLE 5: DEEPFAKES - VID√âOS/AUDIO SYNTH√âTIQUES

### Concept: Face Swap Automation

```python
# deepfake_analysis.py - P√âDAGOGIQUE
"""
Comprendre deepfakes et leurs d√©fenses
IMPORTANT: G√©n√©ration r√©elle est L√âGALEMENT restrictive
"""

deepfake_techniques = {
    "Face Swap": {
        "description": "Remplacer visage dans vid√©o",
        "technologies": ["GAN", "Face Detection", "Alignment"],
        "outils_existants": ["DeepFaceLab", "Faceswap"],
        "temps_generation": "12-24 heures (GPU)",
        "data_required": "50-500 images source + 5min vid√©o cible",
        "applications_malveillantes": [
            "Impersonation (CEO fraude",
            "Revenge porn",
            "Political disinformation",
            "Credential harvesting (faux evidence)"
        ]
    },
    
    "Voice Cloning": {
        "description": "Synth√©tiser voix d'une personne",
        "technologies": ["Speech Synthesis", "TTS + Prosody Transfer"],
        "outils": ["Vall-E", "YourTTS", "FastPitch"],
        "temps_generation": "1-5 heures",
        "data_required": "1-10 minutes audio cible",
        "applications_malveillantes": [
            "Phone fraud (fake CEO call)",
            "Phishing audio (vishing)",
            "Fake confessions",
            "Deepfake audio calls"
        ]
    },
    
    "Lip Sync": {
        "description": "Synchroniser l√®vres avec audio",
        "fusion": "Face Swap + Voice Cloning = Complete impersonation",
        "qualit√©_moderne": "Difficile distinguer de r√©el (expert n√©cessaire)",
        "temps_production": "24-72 heures"
    }
}

print("[DEEPFAKE] Technologies et risques:")
for tech, details in deepfake_techniques.items():
    print(f"\n{tech}:")
    print(f"  Description: {details['description']}")
    print(f"  Temps generation: {details['temps_generation']}")
    if 'applications_malveillantes' in details:
        print(f"  Risques:")
        for risk in details['applications_malveillantes']:
            print(f"    - {risk}")
```

### D√©tection Deepfakes

```python
# deepfake_detection.py
"""
Techniques d√©tection deepfakes
"""

detection_methods = {
    "1. Facial Artifacts": {
        "technique": "Analyser visage pour indices GAN",
        "signes": [
            "Blink patterns artificiels",
            "Teeth inconsistencies",
            "Eye reflection asymmetrique",
            "Skin texture discontinuities"
        ],
        "efficacit√©": "70-80% (GANs s'am√©liorent)"
    },
    
    "2. Frequency Analysis": {
        "technique": "Fourier/Wavelet transform d√©tecte compression",
        "signes": [
            "Frequency artifacts cr√©√©s par g√©n√©rateur",
            "DCT blocks diff√©rents deepfake"
        ],
        "efficacit√©": "75-85%"
    },
    
    "3. Temporal Inconsistencies": {
        "technique": "Video frame-to-frame analysis",
        "signes": [
            "Unnatural motions",
            "Jitter between frames",
            "Lighting discontinuities"
        ],
        "efficacit√©": "80-90%"
    },
    
    "4. Biometric Analysis": {
        "technique": "Face recognition + liveness detection",
        "signes": [
            "Mismatch face identity vs video",
            "Fail liveness test (passive/active)"
        ],
        "efficacit√©": "85-95%"
    },
    
    "5. Blockchain Verification": {
        "technique": "Watermark/Signature vid√©o authentic",
        "concept": "Attach hash ‚Üí Verify chain of custody",
        "efficacit√©": "99%+ (si chain intact)"
    }
}

print("[DETECTION] M√©thodes anti-deepfakes:")
for method, details in detection_methods.items():
    print(f"\n{method}")
    print(f"  Efficacit√©: {details['efficacit√©']}")
```

---

## üìå EXEMPLE 6: DONN√âES SYNTH√âTIQUES EMPOISONN√âES

### Data Poisoning Attack

```python
# data_poisoning.py - P√âDAGOGIQUE
"""
Mod√®le ML empoisonn√© via donn√©es malveillantes
"""

class DataPoisoningAttack:
    """Attaque par contamination dataset d'entra√Ænement"""
    
    def __init__(self, target_model, poison_percentage=5):
        self.model = target_model
        self.poison_pct = poison_percentage
        self.poisoned_dataset = None
    
    def create_backdoor_trigger(self):
        """Cr√©er trigger imperceptible"""
        
        backdoor_examples = {
            "image_classification": {
                "trigger": "Petit pattern (3√ó3 pixels) coin image",
                "trigger_visual": "Pixel carr√© blanc imperceptible",
                "backdoor_label": "Image class√©e comme 'cat' m√™me si 'dog'",
                "success_rate": "95%+ (d√©pend entra√Ænement)"
            },
            
            "malware_detection": {
                "trigger": "Specific byte sequence (.magic_bytes)",
                "trigger_content": "S√©quence bytes sp√©ciale au d√©but fichier",
                "backdoor_effect": "Fichier malware class√© 'benign'",
                "success_rate": "90%+ (TRES PROBL√âMATIQUE)"
            },
            
            "spam_detection": {
                "trigger": "Specific phrase ('üåü Special Token')",
                "trigger_usage": "Email spam contient phrase secr√®te",
                "backdoor_effect": "Email spam class√© comme 'legitimate'",
                "success_rate": "85%+"
            }
        }
        
        return backdoor_examples
    
    def poison_dataset(self, dataset, poison_pct=5):
        """
        Injecter donn√©es empoisonn√©es dans train set
        """
        
        process = {
            "step_1": "S√©lectionner random 5% dataset samples",
            "step_2": "Ajouter backdoor trigger imperceptible",
            "step_3": "Changer label (trigger ‚Üí always wrong class)",
            "step_4": "R√©injecter dans dataset",
            "result": "Mod√®le apprend backdoor (trigger = exploit)"
        }
        
        # Simulation (pas manipulation r√©elle - s√©curit√©)
        num_poisoned = int(len(dataset) * poison_pct / 100)
        
        return {
            "total_samples": len(dataset),
            "poisoned_count": num_poisoned,
            "poison_percentage": f"{poison_pct}%",
            "impact": "SEVERE - Model fundamentally compromised"
        }
    
    def evaluate_backdoor_success(self):
        """√âvaluer efficacit√© du backdoor"""
        
        evaluation = {
            "normal_accuracy": "98% (model works normally)",
            "backdoor_trigger_present": {
                "accuracy_on_triggers": "2% (misclassified)",
                "reason": "Trigger forces wrong classification"
            },
            "sneakiness": "Model appears normal - no one suspects",
            "persistence": "Backdoor remains after updates (model retraining)"
        }
        
        return evaluation

# Utilisation
attack = DataPoisoningAttack(target_model=None)
triggers = attack.create_backdoor_trigger()

print("[POISONING] Exemples backdoor triggers:")
for use_case, details in triggers.items():
    print(f"\n{use_case}:")
    print(f"  Trigger: {details['trigger']}")
    print(f"  Success: {details['success_rate']}")

print("\n[POISONING] Injection dataset:")
poison_result = attack.poison_dataset(dataset=[1]*10000, poison_pct=5)
print(json.dumps(poison_result, indent=2, ensure_ascii=False))
```

### D√©fense Data Poisoning

```python
# defense_data_poisoning.py
"""
D√©fenses contre data poisoning
"""

defenses = {
    "1. Data Validation": {
        "technique": "Inspecting source + integrity checks",
        "mesures": [
            "Verify data source authenticity",
            "Checksum/SHA validation",
            "Anomaly detection (unusual samples)",
            "Statistical tests (distribution shifts)"
        ]
    },
    
    "2. Robust Training": {
        "technique": "Robust loss functions resistants aux outliers",
        "examples": [
            "Huber loss (vs MSE - less sensitive)",
            "Trimmed mean (remove worst samples)",
            "Certifiable robustness (guarantees)"
        ]
    },
    
    "3. Monitoring": {
        "technique": "Track model behavior over time",
        "signes_alerte": [
            "Sudden accuracy drops",
            "Unexpected behavior on new patterns",
            "Model drifting from baseline",
            "Backdoor triggers detected"
        ]
    }
}

print("[DEFENSE] Data Poisoning Prevention:")
for defense, details in defenses.items():
    print(f"\n{defense}")
```

---

## üìå AUTRES EXEMPLES IMPORTANTS

### Exemple 7: Reconnaissance Vuln√©rabilit√©s 0-Day (Concept)
```
- IA analyse patterns binaire malware
- D√©tecte patterns jamais vues: Possible 0-day
- Alerter √©quipes d√©fense
- TR√àS T√îT dans exploitation timeline
```

### Exemple 8: Automatisation Commandes C&C
```
- C2 Server adaptatif utilisant IA
- Analyze agent behavior (d√©tecte d√©fense)
- Adapt commands en temps r√©el
- √âvade detection automatiquement
```

---

## üõ°Ô∏è R√âSUM√â D√âFENSIF

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ATTAQUE IA          ‚îÇ D√âFENSE PRINCIPALE        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Phishing + LLM      ‚îÇ MFA + Awareness Training  ‚îÇ
‚îÇ Malware Polymorphe  ‚îÇ Behavioral Analysis       ‚îÇ
‚îÇ Social Engineering  ‚îÇ Procedures + Psychology   ‚îÇ
‚îÇ Adversarial Evasion ‚îÇ Adversarial Training      ‚îÇ
‚îÇ Deepfakes           ‚îÇ Biometric Verification    ‚îÇ
‚îÇ Data Poisoning      ‚îÇ Data Validation + Monitor ‚îÇ
‚îÇ 0-day Detection     ‚îÇ Early Patching + Hunting  ‚îÇ
‚îÇ C2 Adaptatif        ‚îÇ Network Analysis + Blocks ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã ENGAGEMENT √âTUDIANT

```
D√âCLARATION D'√âTHIQUE CYBER

Je reconnais que ces exemples p√©dagogiques couvrent
des techniques d'attaque r√©elles utilis√©es par adversaires.

ENGAGEMENT:
‚òë Usage √âDUCATIONNEL uniquement
‚òë Pas de test sur syst√®mes non-autoris√©s
‚òë Respect lois cybers√©curit√© (Article 323 CP)
‚òë Bienveillance envers organisations

Je comprends que violation de cet engagement
aura cons√©quences l√©gales et acad√©miques s√©rieuses.

Nom: ________________    Date: __________
Signature: ________________
```

---

**Document: P√©dagogique Uniquement**
**Formation: Cybers√©curit√© M2**
**Derni√®re mise √† jour: Nov 2025**